{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Pointer-Generator Network, Beam Search and Bidirectional RNN Seq2Seq Model in Keras**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nimport keras\nfrom keras.layers import Embedding, Dense, LSTM, Input, TimeDistributed, Bidirectional\nfrom keras.models import Model\n\n\"\"\"Attention mechanism\"\"\"\n# Define an attention layer\nclass Attention(keras.Model):\n    def __init__(self, units):\n        super(Attention, self).__init__()\n        self.W1 = Dense(units)\n        self.W2 = Dense(units)\n        self.V = Dense(1)\n \n    def call(self, features, hidden):\n        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n        context_vector = attention_weights * features\n        context_vector = tf.reduce_sum(context_vector, axis=1)   \n        \n        return context_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nSome parameters:\n\nnum_encoder_tokens = ?\nnum_decoder_tokens = ?\nvocab_size = ?\nembedding_size = ?\nrnn_cell_size = ?\n\n\"\"\"\n\n\n\"\"\"Embedding layer\"\"\"\n\nembedding_inputs = Input(shape=(None, num_encoder_tokens))\nembedding_layer = Embedding(vocab_size, embedding_size) \n\nencoder_inputs = embedding_layer(embedding_inputs)\n\n\n\"\"\"The bidirectional encoder with LSTM\"\"\"\n\nencoder = Bidirectional(LSTM(256, dropout=0.2,\n                            recurrent_dropout=0.2,\n                            return_sequences=True,\n                            return_state=True,\n                            recurrent_activation='relu',\n                            recurrent_initializer='glorot_uniform'), name=\"bi_lstm_0\")(encoder_inputs)\n\nencoder_output, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(rnn_cell_size,\n                                                                            dropout=0.2,\n                                                                            recurrent_dropout=0.2,\n                                                                            return_sequences=True,\n                                                                            return_state=True,\n                                                                            recurrent_activation='relu',\n                                                                            recurrent_initializer='glorot_uniform'))(encoder)\n\n\"\"\"Concatenate the results of the two directions as the encoder states\"\"\"\nencoder_state_h = Concatenate()([forward_h, backward_h])\nencoder_state_c = Concatenate()([forward_c, backward_c])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"Calculate attention distribution, P_vocab = softmax(V2(V1([context_vector, decoder_state])+b1)+b2)\"\"\"\n\ndef Attn_dist(context_vector, decoder_state, units):\n    v1 = Dense(units)\n    v2 = Dense(units)\n    e = Concatenate()([decoder_state, context_vector])\n    P_vocab = tf.nn.softmax(v2(v1(e))) #need to specify axis?\n    \n    return P_vocab","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend\n\n\ndecoder_inputs = Input(shape=(None, num_decoder_tokens))\nencoder_states = [encoder_state_h, encoder_state_c]\n\n\"\"\"Unidirectional decoder LSTM\"\"\"\ndecoder = LSTM(rnn_cell_size,\n               dropout=0.2,\n               recurrent_dropout=0.2,\n               return_sequences=True,\n               return_state=True,\n               recurrent_activation='relu')\n\n#decoder_out contains all the hidden states for all time steps. decoder_state_h is the final hidden state output\ndecoder_out, decoder_state_h, decoder_state_c = decoder(decoder_inputs, initial_state = encoder_states)\n\n\n\n\"\"\"Use the attention network to obtain the context vector, then calculate attention distribution\"\"\"\nunits = ?\n\nattention = Attention(units) \ncontext_vector = attention.call(decoder_state_h, decoder_output)\n\nattn_dist = Attn_dist(context_vector, decoder_state_h)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Incomplete decoder: need coverage mechanism and final_dist calc (output calc)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef linear(args, output_size, bias, bias_start=0.0, scope=None):\n  \"\"\"\n    args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n    output_size: int, second dimension of W[i].\n    bias: boolean, whether to add a bias term or not.\n    bias_start: starting value to initialize the bias; 0 by default.\n    scope: VariableScope for the created subgraph; defaults to \"Linear\".\n  Returns:\n    A 2D Tensor with shape [batch x output_size] equal to\n    sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n  Raises:\n    ValueError: if some of the arguments has unspecified or wrong shape.\n  \"\"\"\n  if args is None or (isinstance(args, (list, tuple)) and not args):\n    raise ValueError(\"`args` must be specified\")\n  if not isinstance(args, (list, tuple)):\n    args = [args]\n\n  # Calculate the total size of arguments on dimension 1.\n  total_arg_size = 0\n  shapes = [a.get_shape().as_list() for a in args]\n  for shape in shapes:\n    if len(shape) != 2:\n      raise ValueError(\"Linear is expecting 2D arguments: %s\" % str(shapes))\n    if not shape[1]:\n      raise ValueError(\"Linear expects shape[1] of arguments: %s\" % str(shapes))\n    else:\n      total_arg_size += shape[1]\n\n  # Computation.\n  with tf.variable_scope(scope or \"Linear\"):\n    matrix = tf.get_variable(\"Matrix\", [total_arg_size, output_size])\n    if len(args) == 1:\n      res = tf.matmul(args[0], matrix)\n    else:\n      res = tf.matmul(tf.concat(axis=1, values=args), matrix)\n    if not bias:\n      return res\n    bias_term = tf.get_variable(\n        \"Bias\", [output_size], initializer=tf.constant_initializer(bias_start))\n    \n  return res + bias_term\n\n\n# Calculate p_gen and organize output\np_gens = []\noutputs = []\n\n\np_gen = linear([context_vector, decoder_state_c, decoder_state_h, decider_inputs], 1, True) \np_gen = tf.sigmoid(p_gen)\np_gens.append(p_gen)\n\n\n\noutput = linear([decoder_out] + [context_vector], len(decoder_out), True) #decoder ouput size = len(decoder_out)\noutputs.append(output)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Beam Search Decoder (for inference)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Beam search output, returning top_paths possible output sequences and their log likelihoods'''\ndecoder = backend.ctc_decode(OUTPUT,\n                            input_length = context_vector.shape[0]\n                            greedy=False,\n                            beam_width=5\n                            top_paths=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf \n\nprint(tf.test.gpu_device_name())\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}